## 第三次实验报告

### 运行代码

```bash
python src/main.py -f data/Tweets.txt -l log/logfile.log
```

### 实验环境与实验数据

* CPU -- i7-8700K
* 内存 -- 15.6 GB
* 实验数据: [Tweets.txt]()

### 实验目的

熟悉 sklearn 库中的常用聚类算法 API, 对 Tweets 数据进行聚类, 并比较效果.

### 实验步骤

#### 读取数据

对 『Tweets.txt 』中的数据进行读取, 每一条数据都是是 『JSON 』格式的,所以通过 Python 的 『json』 模块对 『Tweets.txt』 中数据的每一行进行读取.

实现文件: 『src/main.py』

#### 聚类

通过 sklearn 库中的 API, 对数据进行聚类.运用了如下几个方法:

* KMeans
* AffinityPropagation
* MeanShift
* SpectralClustering
* Ward Hierarchical Clustering
* AgglomerativeClustering
* DBSCAN
* GaussianMixture

进行聚类.

##### KMeans

![5ç§ä¸"è¦èç±"ç®æ³çç®åä"ç"](http://imgcdn.atyun.com/2018/03/1-KrcZK0xYgTa4qFrVr0fO2w.gif)

1.首先，选择一些类/组来使用并随机地初始化它们各自的中心点。

2.每个数据点通过计算点和每个组中心之间的距离进行分类，然后将这个点分类为最接近它的组。

3.基于这些分类点，我们通过取组中所有向量的均值来重新计算组中心。

4.对一组迭代重复这些步骤。

K-Means聚类算法的优势在于它的速度非常快，因为所做的只是计算点和群中心之间的距离;它有一个线性复杂度*O*(*n*)。

另一方面，K-Means也有几个缺点。首先，你必须选择有多少组/类。这并不是不重要的事，理想情况下，我们希望它能帮我们解决这些问题，因为它的关键在于从数据中获得一些启示。K-Means也从随机选择的聚类中心开始，因此在不同的算法运行中可能产生不同的聚类结果。因此，结果可能是不可重复的，并且缺乏一致性。其他聚类方法更加一致。

对应 sklearn 中的 API 为: KMeans

##### AffinityPropagation

##### MeanShift

##### SpectralClustering

##### Ward Hierarchical Clustering

##### AgglomerativeClustering

##### DBSCAN

##### GaussianMixture



