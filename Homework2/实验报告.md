## Naive Bayesian Classification 实验报告

### 运行代码

```bash
python nbc.py
```



### 实验环境与实验数据

* CPU -- i5-4570

* 内存 -- 8GB
* 实验数据: [20news-18828](http://qwone.com/~jason/20Newsgroups/)

### 实验目的

运用 Naive Bayesian Classification 的方法通过对已有标签的文档进行操作，最终实现对无标签的文档进行正确分类。

### 实验步骤

#### 数据划分

* 60% 的 Train 数据

* 40% 的 Test 数据

为保证数据的均匀分布，从每个类中挑选相同比例的数据组成训练集、测试集。沿用了上一个 Homework 采用的数据集，由于 NBC 方法中所调超参数较少，所以将验证集与测试集合并为测试集。

#### 词干提取与词频统计

首先需要对实验中所有文档进行词干提取和词频统计，这里是将数据包括训练集、验证集、测试集全部进行统计，由于实验数据量过大，提取词干和统计词频所耗费的时间会很多，为了节省时间，将所有统计结果保存到文件中，以便用之后的每次实验。

运用『TextBlob』进行词干提取得到一个list，再用『collections.Counter』对list的每项进行计数，存储到一个字典中，键值为 文件名，对应的值为词频结果。统计结果保存到『data/tf.txt』。

实现文件：『src/utils.py』

#### 模型训练

分为三种模型，训练过程是相同的：

1. 计算每一类文本出现的概率 $p(d_i) = \frac{c(d_i)}{c(d)}$
2. 建立字典，确立一个大的空间，保证每一类文档的特征都是相同的
3. 统计每一类文档对应的词频,这里 伯努利模型与多项式模型、混合模型是不同的，伯努利模型不重复统计同一文档中多次出现的词。
4. 再将计算特征 -- 词的概率 $p(w|d_i) = \frac{c(w)}{c(w_{d_itotal})}$

至此模型训练完毕。

实现文件：『src/Model.py』

#### 测试模型

在测试模型中会遇到如下问题，测试集中有的词没有在训练好的模型中，这样会导致这个词的概率为0，从而影响模型分类的结果，这里用到了一个小 trick -- 平滑技术。平滑技术分为两种：

* 对于多项式模型，$p(w|d_i) = \frac{c(w) + 1}{c(w_{d_itotal})+c(w_{total})}$
* 对于伯努利模型，$p(w|d_i) = \frac{c(w) + 1}{c(w_{d_itotal})+c(d)}$

这样，即使$c(w)$为0也不会使预测概率为0。由于每一项的概率很小，大概是 10e-3 级别，所以为了方便运算，对每一项都取对数，简化计算。由贝叶斯定理可得：

$$p(d_i|x_1,x_2....x_n) = \frac{p(x_1,x_2,.....x_n|d_i) * p(d_i)}{p(x_1,x_2,.....x_n)}$$

而由于对于同一文档，$p(x_1,x_2,.....x_n)$是相同的，所以我们只需要计算$p(x_1,x_2,.....x_n|d_i) * p(d_i)$即可，对该式子取对数得到 $\sum{log p(x_i|d_i)} + logp(d_i)$。

### 遇到的问题

一开始我采用的是对每一类文档提取一次字典，正确率只有 3%左右。更换成全局字典之后，效果提升非常明显...

### 实验结果

实验结果保存到 『../log/logout.log』中

#### 多项式模型结果

> PolynomialModel Test Finished cost time 23.390124082565308s, Predict accuary is 6232 / 7517, 82.90541439404018%

#### 伯努利模型结果

> BernoulliModel Test Finished cost time 26.7016499042511s, Predict accuary is 6445 / 7517, 85.73899161899693%

#### 混合模型结果

> MixModel Test Finished cost time 31.27314591407776s, Predict accuary is 6192 / 7517, 82.37328721564454%





 